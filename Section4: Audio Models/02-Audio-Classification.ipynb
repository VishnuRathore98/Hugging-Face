{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "844859b3",
   "metadata": {},
   "source": [
    "# Audio Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8fdeb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, ASTForAudioClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b158849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vpsr/Desktop/python/Hugging Face/.venv/lib/python3.12/site-packages/transformers/audio_utils.py:349: UserWarning: At least one mel filter has all zero values. The value for `num_mel_filters` (128) may be set too high. Or, the value for `num_frequency_bins` (257) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "862fed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "audio_path = 'example.mp3'\n",
    "y, sr = librosa.load(audio_path, sr=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb9166",
   "metadata": {},
   "source": [
    "### Sampling Rate Issues\n",
    "\n",
    "Most ML models are trained on 16 kHz sampling rate, we will run into issues if we try to force our own sampling rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c46fa129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ERROR!\n",
    "# result = feature_extractor(y,sampling_rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2952be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to `ASTFeatureExtractor()`. Failing to do so can result in silent errors that might be hard to debug.\n"
     ]
    }
   ],
   "source": [
    "result = feature_extractor(y,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503e9cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ASTForAudioClassification.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32d6df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_logits = model(result['input_values']).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8484acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_class_ids = torch.argmax(prediction_logits, dim=-1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d984b9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label = model.config.id2label[predicted_class_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01e99570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Music'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170686e2",
   "metadata": {},
   "source": [
    "### Pipeline for Audio Classification\n",
    "Using a pipeline as high-level helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97611044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "316c5e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\"audio-classification\", model=\"MIT/ast-finetuned-audioset-10-10-0.4593\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68c15fb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASTForAudioClassification(\n",
       "  (audio_spectrogram_transformer): ASTModel(\n",
       "    (embeddings): ASTEmbeddings(\n",
       "      (patch_embeddings): ASTPatchEmbeddings(\n",
       "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ASTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ASTLayer(\n",
       "          (attention): ASTAttention(\n",
       "            (attention): ASTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (output): ASTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ASTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ASTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): ASTMLPHead(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=768, out_features=527, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a0e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pipe(\"example.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edad2920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16a7dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5 = predictions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb1ef721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4848681092262268, 'label': 'Music'},\n",
       " {'score': 0.19131147861480713, 'label': 'Violin, fiddle'},\n",
       " {'score': 0.08519703149795532, 'label': 'Musical instrument'},\n",
       " {'score': 0.046924445778131485, 'label': 'Bowed string instrument'},\n",
       " {'score': 0.04536091908812523, 'label': 'Orchestra'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f2b2d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music                      48.49 %\n",
      "Violin, fiddle             19.13 %\n",
      "Musical instrument          8.52 %\n",
      "Bowed string instrument     4.69 %\n",
      "Orchestra                   4.54 %\n"
     ]
    }
   ],
   "source": [
    "for result in top_5:\n",
    "    print(f\"{result['label']:<25} {float(result['score']*100):>6.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0715cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
